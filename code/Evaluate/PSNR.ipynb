{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea78e3-f16e-4d59-8bf3-d93eb21181a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "sys.path.append('/home/lyy/CVAE_GAN/rockgan')\n",
    "sys.path.append('/home/lyy/CVAE_GAN/')\n",
    "from architecture_vae import VAEGenerator  \n",
    "from rockgan.utils import MyLoader  \n",
    "from torch.utils.data import Dataset\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b730f-6ab9-4f57-9e8d-f7272efbb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, latent_dim=32, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, label_embedding_dim)\n",
    "        self.conv1 = nn.Conv3d(in_channels + label_embedding_dim, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_mu = nn.Conv3d(64, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "        self.conv4_log_var = nn.Conv3d(64, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        label_embedding = label_embedding.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        label_embedding = label_embedding.expand(-1, -1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        x = torch.cat([x, label_embedding], dim=1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        mu = self.conv4_mu(x)\n",
    "        log_var = self.conv4_log_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class VAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32, out_channels=1, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, label_embedding_dim)\n",
    "        self.conv_trans1 = nn.ConvTranspose3d(latent_dim + label_embedding_dim, 32, kernel_size=4, stride=1, padding=0)\n",
    "        self.conv_trans2 = nn.ConvTranspose3d(32, 16, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv_trans3 = nn.ConvTranspose3d(16, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_trans4 = nn.ConvTranspose3d(4, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.output_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z, label_embedding):\n",
    "        \n",
    "        label_embedding = label_embedding.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        label_embedding = label_embedding.expand(-1, -1, z.shape[2], z.shape[3], z.shape[4])  \n",
    "        z = torch.cat([z, label_embedding], dim=1)\n",
    "        z = F.gelu(self.conv_trans1(z))\n",
    "        z = F.gelu(self.conv_trans2(z))\n",
    "        z = F.gelu(self.conv_trans3(z))\n",
    "        z = self.conv_trans4(z)\n",
    "        return self.output_layer(z)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_channels=1, latent_dim=32, out_channels=1, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = VAEEncoder(in_channels, latent_dim, num_classes, label_embedding_dim)\n",
    "        self.decoder = VAEDecoder(latent_dim, out_channels, num_classes, label_embedding_dim)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        mu, log_var = self.encoder(x, label_embedding)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        recon_x = self.decoder(z, label_embedding)\n",
    "        return recon_x, mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "\n",
    "class VAEGenerator(nn.Module):\n",
    "    def __init__(self, in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEGenerator, self).__init__()\n",
    "        self.vae = VAE(in_channel, latent_dim, out_channel, num_classes, label_embedding_dim)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        recon_x, mu, log_var = self.vae(x, label_embedding)\n",
    "        return recon_x, mu, log_var\n",
    "        \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a6de2-4b8c-4925-9acf-d51665a538ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data = np.load('../data/2_subpatches.npy')[364:365]   \n",
    "real_data = torch.tensor(real_data, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_2_embedding = label_embedding_layer(torch.tensor([0], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_2, log_var_2 = vae_generator.vae.encoder(real_data, label_2_embedding)\n",
    "    z_2 = vae_generator.vae.reparameterize(mu_2, log_var_2)\n",
    "\n",
    "    \n",
    "    generated_image = vae_generator.vae.decoder(z_2, label_2_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = generated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=1)\n",
    "    \n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_images = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "print(binary_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8ec38f-a1ad-47f0-8818-45f6757ff4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "real_images = real_data[0][0].cpu().numpy()\n",
    "print(real_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e0a33-62e0-42bd-a5f6-c7525dd2a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(real_images, generated_images):\n",
    "\n",
    "    psnr_values = []\n",
    "    for real_image, generated_image in zip(real_images, generated_images):\n",
    "        psnr_value = compare_psnr(real_image, generated_image, data_range=1.0) \n",
    "        print(f\"这张图片的PSNR值为{psnr_value}\")\n",
    "        psnr_values.append(psnr_value)\n",
    "    \n",
    "\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    return avg_psnr\n",
    "\n",
    "\n",
    "real_images = real_images = real_data[0][0].cpu().numpy()  \n",
    "generated_images = binary_images  \n",
    "\n",
    "avg_psnr_value = compute_psnr(real_images, generated_images)\n",
    "print(f\"Average PSNR (dB): {avg_psnr_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e881f8-cd66-4044-9a66-5ab4d97e7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(real_images, generated_images):\n",
    "\n",
    "    ssim_values = []\n",
    "    for real_image, generated_image in zip(real_images, generated_images):\n",
    "        \n",
    "        ssim_value, _ = compare_ssim(real_image, generated_image, data_range=1, full=True)\n",
    "        ssim_values.append(ssim_value)\n",
    "    \n",
    "    \n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    return avg_ssim\n",
    "\n",
    "\n",
    "real_images = real_data[0][0].cpu().numpy()  \n",
    "generated_images = binary_images  \n",
    "\n",
    "\n",
    "avg_ssim_value = compute_ssim(real_images, generated_images)\n",
    "print(f\"Average SSIM: {avg_ssim_value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockgan",
   "language": "python",
   "name": "rockgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
