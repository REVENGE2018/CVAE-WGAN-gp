{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea78e3-f16e-4d59-8bf3-d93eb21181a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.ndimage import zoom\n",
    "sys.path.append('/home/lyy/CVAE_GAN/rockgan')\n",
    "sys.path.append('/home/lyy/CVAE_GAN/')\n",
    "from architecture_vae import VAEGenerator  \n",
    "from rockgan.utils import MyLoader  \n",
    "from torch.utils.data import Dataset\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b730f-6ab9-4f57-9e8d-f7272efbb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, latent_dim=32, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, label_embedding_dim)\n",
    "        self.conv1 = nn.Conv3d(in_channels + label_embedding_dim, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_mu = nn.Conv3d(64, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "        self.conv4_log_var = nn.Conv3d(64, latent_dim, kernel_size=4, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        label_embedding = label_embedding.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        label_embedding = label_embedding.expand(-1, -1, x.shape[2], x.shape[3], x.shape[4])\n",
    "        x = torch.cat([x, label_embedding], dim=1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        mu = self.conv4_mu(x)\n",
    "        log_var = self.conv4_log_var(x)\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class VAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32, out_channels=1, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, label_embedding_dim)\n",
    "        self.conv_trans1 = nn.ConvTranspose3d(latent_dim + label_embedding_dim, 32, kernel_size=4, stride=1, padding=0)\n",
    "        self.conv_trans2 = nn.ConvTranspose3d(32, 16, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv_trans3 = nn.ConvTranspose3d(16, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_trans4 = nn.ConvTranspose3d(4, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.output_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z, label_embedding):\n",
    "        \n",
    "        label_embedding = label_embedding.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "        label_embedding = label_embedding.expand(-1, -1, z.shape[2], z.shape[3], z.shape[4])  \n",
    "        z = torch.cat([z, label_embedding], dim=1)\n",
    "        z = F.gelu(self.conv_trans1(z))\n",
    "        z = F.gelu(self.conv_trans2(z))\n",
    "        z = F.gelu(self.conv_trans3(z))\n",
    "        z = self.conv_trans4(z)\n",
    "        return self.output_layer(z)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_channels=1, latent_dim=32, out_channels=1, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = VAEEncoder(in_channels, latent_dim, num_classes, label_embedding_dim)\n",
    "        self.decoder = VAEDecoder(latent_dim, out_channels, num_classes, label_embedding_dim)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        mu, log_var = self.encoder(x, label_embedding)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        recon_x = self.decoder(z, label_embedding)\n",
    "        return recon_x, mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "\n",
    "class VAEGenerator(nn.Module):\n",
    "    def __init__(self, in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16):\n",
    "        super(VAEGenerator, self).__init__()\n",
    "        self.vae = VAE(in_channel, latent_dim, out_channel, num_classes, label_embedding_dim)\n",
    "\n",
    "    def forward(self, x, label_embedding):\n",
    "        recon_x, mu, log_var = self.vae(x, label_embedding)\n",
    "        return recon_x, mu, log_var\n",
    "        \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29857272-546c-4c7d-a69a-f05b7289dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data = np.load('../data/2_subpatches.npy')[364:365]   \n",
    "real_data = torch.tensor(real_data, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_2_embedding = label_embedding_layer(torch.tensor([0], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_2, log_var_2 = vae_generator.vae.encoder(real_data, label_2_embedding)\n",
    "    z_2 = vae_generator.vae.reparameterize(mu_2, log_var_2)\n",
    "\n",
    "    \n",
    "    generated_image = vae_generator.vae.decoder(z_2, label_2_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = generated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=1)\n",
    "    \n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_image = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "    \n",
    "    tiff.imwrite('2.tiff', binary_image)\n",
    "\n",
    "    \n",
    "    slice_index = binary_image.shape[0] // 2  \n",
    "    plt.imshow(binary_image[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Binary Image (Otsu Threshold = {otsu_threshold})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5d970-4324-478d-8382-2f2018937a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data = np.load('../data/5_subpatches.npy')[364:365]   \n",
    "real_data = torch.tensor(real_data, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_5_embedding = label_embedding_layer(torch.tensor([1], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_5, log_var_5 = vae_generator.vae.encoder(real_data, label_5_embedding)\n",
    "    z_5 = vae_generator.vae.reparameterize(mu_5, log_var_5)\n",
    "\n",
    "    \n",
    "    generated_image = vae_generator.vae.decoder(z_5, label_5_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = generated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    \n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=1)\n",
    "    \n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_image = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "    \n",
    "    tiff.imwrite('5.tiff', binary_image)\n",
    "\n",
    "    \n",
    "    slice_index = binary_image.shape[0] // 2  \n",
    "    plt.imshow(binary_image[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Binary Image (Otsu Threshold = {otsu_threshold})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c729a61-f35e-4550-8719-e6b616367c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data = np.load('../data/6_subpatches.npy')[364:365]   \n",
    "real_data = torch.tensor(real_data, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_6_embedding = label_embedding_layer(torch.tensor([2], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_6, log_var_6 = vae_generator.vae.encoder(real_data, label_6_embedding)\n",
    "    z_6 = vae_generator.vae.reparameterize(mu_6, log_var_6)\n",
    "\n",
    "    \n",
    "    generated_image = vae_generator.vae.decoder(z_6, label_6_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = generated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    \n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=1)\n",
    "    \n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_image = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "    \n",
    "    tiff.imwrite('6.tiff', binary_image)\n",
    "\n",
    "    \n",
    "    slice_index = binary_image.shape[0] // 2  \n",
    "    plt.imshow(binary_image[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Binary Image (Otsu Threshold = {otsu_threshold})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7004b7d-fde4-4b11-8b76-0fe25b58008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data_2 = np.load('../data/2_subpatches.npy')[364:365]   \n",
    "real_data_5 = np.load('../data/5_subpatches.npy')[364:365]   \n",
    "real_data_2 = torch.tensor(real_data_2, dtype=torch.float32).to(device)\n",
    "real_data_5 = torch.tensor(real_data_5, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_2_embedding = label_embedding_layer(torch.tensor([0], device=device))  \n",
    "label_5_embedding = label_embedding_layer(torch.tensor([1], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_2, log_var_2 = vae_generator.vae.encoder(real_data_2, label_2_embedding)\n",
    "    z_2 = vae_generator.vae.reparameterize(mu_2, log_var_2)\n",
    "    \n",
    "    \n",
    "    mu_5, log_var_5 = vae_generator.vae.encoder(real_data_5, label_5_embedding)\n",
    "    z_5 = vae_generator.vae.reparameterize(mu_5, log_var_5)\n",
    "\n",
    "    \n",
    "    alpha = 0.5  \n",
    "    z_interpolated = (1 - alpha) * z_2 + alpha * z_5  \n",
    "\n",
    "    \n",
    "    label_interpolated_embedding = (1 - alpha) * label_2_embedding + alpha * label_5_embedding\n",
    "    \n",
    "    \n",
    "    interpolated_image = vae_generator.vae.decoder(z_interpolated, label_interpolated_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = interpolated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    \n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=1.5)\n",
    "\n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_image = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "    \n",
    "    tiff.imwrite('2_5.tiff', binary_image)\n",
    "\n",
    "    \n",
    "    slice_index = binary_image.shape[0] // 2  \n",
    "    plt.imshow(binary_image[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Binary Image Interpolated (Otsu + Median Filter)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d84ce-e5f1-450e-9290-b72e7f7f03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vae_generator = VAEGenerator(in_channel=1, out_channel=1, latent_dim=32, num_classes=3, label_embedding_dim=16).to(device)\n",
    "vae_generator.load_state_dict(torch.load('vae_generator_epoch_100.pth', map_location=device))\n",
    "vae_generator.eval()\n",
    "\n",
    "\n",
    "real_data_5 = np.load('../data/5_subpatches.npy')[364:365]   \n",
    "real_data_6 = np.load('../data/6_subpatches.npy')[364:365]   \n",
    "real_data_5 = torch.tensor(real_data_5, dtype=torch.float32).to(device)\n",
    "real_data_6 = torch.tensor(real_data_6, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "label_embedding_layer = vae_generator.vae.encoder.label_emb\n",
    "label_5_embedding = label_embedding_layer(torch.tensor([1], device=device))  \n",
    "label_6_embedding = label_embedding_layer(torch.tensor([2], device=device))  \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mu_5, log_var_5 = vae_generator.vae.encoder(real_data_5, label_5_embedding)\n",
    "    z_5 = vae_generator.vae.reparameterize(mu_5, log_var_5)\n",
    "    \n",
    "    \n",
    "    mu_6, log_var_6 = vae_generator.vae.encoder(real_data_6, label_6_embedding)\n",
    "    z_6 = vae_generator.vae.reparameterize(mu_6, log_var_6)\n",
    "\n",
    "    \n",
    "    alpha = 0.5  \n",
    "    z_interpolated = (1 - alpha) * z_5 + alpha * z_6  \n",
    "\n",
    "    \n",
    "    label_interpolated_embedding = (1 - alpha) * label_5_embedding + alpha * label_6_embedding\n",
    "\n",
    "    \n",
    "    interpolated_image = vae_generator.vae.decoder(z_interpolated, label_interpolated_embedding)\n",
    "\n",
    "    \n",
    "    generated_sample = interpolated_image[0, 0].cpu().numpy()  \n",
    "\n",
    "    \n",
    "    smoothed_sample = gaussian_filter(generated_sample, sigma=2)\n",
    "\n",
    "    \n",
    "    otsu_threshold = threshold_otsu(smoothed_sample)\n",
    "    binary_image = (smoothed_sample > otsu_threshold).astype(np.float32)\n",
    "\n",
    "    \n",
    "    tiff.imwrite('5_6.tiff', binary_image)\n",
    "\n",
    "    \n",
    "    slice_index = binary_image.shape[0] // 2  \n",
    "    plt.imshow(binary_image[slice_index, :, :], cmap='gray')\n",
    "    plt.title(f\"Binary Image Interpolated (5 to 6, Otsu Threshold = {otsu_threshold})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c5f35-d843-4f74-b6c5-854791037783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = '../data/2_subpatches.npy'\n",
    "data = np.load(file_path, mmap_mode='r')\n",
    "data_shape = data.shape\n",
    "print(f\"patch_shape，{data_shape}\")\n",
    "\n",
    "subpatch_count = data.shape[0]  \n",
    "print(f\"subpatch_num，: {subpatch_count}\")\n",
    "\n",
    "subpatch_shape = data.shape[1:]  \n",
    "print(f\"subpatch_shape，: {subpatch_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69eb29-e982-4222-b984-3bc16197d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = '../data/2_subpatches.npy'\n",
    "data = np.load(file_path, mmap_mode='r')\n",
    "\n",
    "\n",
    "output_dir = './segmentation_2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "subpatch_count = data.shape[0]\n",
    "subpatch_shape = data.shape[1:]\n",
    "\n",
    "print(f\"subpatch_num: {subpatch_count}\")\n",
    "print(f\"subpatch_shape: {subpatch_shape}\")\n",
    "\n",
    "\n",
    "for i in range(subpatch_count):\n",
    "    \n",
    "    if i % 100 == 0 and i != 0:\n",
    "        subpatch = data[i]\n",
    "        \n",
    "        tiff_file_path = os.path.join(output_dir, f'2_subpatch_{i+1}.tiff')\n",
    "    \n",
    "        \n",
    "        tiff.imwrite(tiff_file_path, subpatch)\n",
    "        print(f\"subpatch {i+1} saved as: {tiff_file_path}\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Save success！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b441c-d3db-4e30-af81-c2e968c1527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = '../data/5_subpatches.npy'\n",
    "data = np.load(file_path, mmap_mode='r')\n",
    "\n",
    "\n",
    "output_dir = './segmentation_5'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "subpatch_count = data.shape[0]\n",
    "subpatch_shape = data.shape[1:]\n",
    "\n",
    "print(f\"subpatch_num: {subpatch_count}\")\n",
    "print(f\"subpatch_shape: {subpatch_shape}\")\n",
    "\n",
    "\n",
    "for i in range(subpatch_count):\n",
    "    \n",
    "    if i % 100 == 0 and i != 0:\n",
    "        subpatch = data[i]\n",
    "        \n",
    "        tiff_file_path = os.path.join(output_dir, f'5_subpatch_{i+1}.tiff')\n",
    "    \n",
    "        \n",
    "        tiff.imwrite(tiff_file_path, subpatch)\n",
    "        print(f\"subpatch {i+1} saved as: {tiff_file_path}\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Save success！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed8c18-660b-4a80-a58e-6720f0400390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = '../data/6_subpatches.npy'\n",
    "data = np.load(file_path, mmap_mode='r')\n",
    "\n",
    "\n",
    "output_dir = './segmentation_6'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "subpatch_count = data.shape[0]\n",
    "subpatch_shape = data.shape[1:]\n",
    "\n",
    "print(f\"subpatch_num: {subpatch_count}\")\n",
    "print(f\"subpatch_shape: {subpatch_shape}\")\n",
    "\n",
    "\n",
    "for i in range(subpatch_count):\n",
    "    \n",
    "    if i % 100 == 0 and i != 0:\n",
    "        subpatch = data[i]\n",
    "        \n",
    "        tiff_file_path = os.path.join(output_dir, f'6_subpatch_{i+1}.tiff')\n",
    "    \n",
    "        \n",
    "        tiff.imwrite(tiff_file_path, subpatch)\n",
    "        print(f\"subpatch {i+1} saved as: {tiff_file_path}\")\n",
    "    else:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rockgan",
   "language": "python",
   "name": "rockgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
